{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df4931c2",
   "metadata": {},
   "source": [
    "## this generates the larger GeMex dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b59193e",
   "metadata": {},
   "source": [
    "https://huggingface.co/datasets/BoKelvin/GEMeX-ThinkVG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c01ea48",
   "metadata": {},
   "source": [
    "- run it from the med_dataset_large_gen.py script\n",
    "- truncated at 45k, need to make larger "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c31ac0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "# # Try loading the dataset (may fail due to schema mismatch)\n",
    "# ds = load_dataset(\"BoKelvin/GEMeX-VQA\")# , ignore_verifications=True)\n",
    "# print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32daf4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset info for BoKelvin/GEMeX-ThinkVG is available but outdated (commit_hash='aec545fc2bc18dfbc056e00a3a98f113f3a1193d')\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from /localscratch/mlobo6/mlv/huggingface_cache/BoKelvin___ge_me_x-think_vg/default/0.0.0/893bcc6aecff38ed114139f861ebaf755d3d2bb1\n",
      "Found cached dataset ge_me_x-think_vg (/localscratch/mlobo6/mlv/huggingface_cache/BoKelvin___ge_me_x-think_vg/default/0.0.0/893bcc6aecff38ed114139f861ebaf755d3d2bb1)\n",
      "Loading Dataset info from /localscratch/mlobo6/mlv/huggingface_cache/BoKelvin___ge_me_x-think_vg/default/0.0.0/893bcc6aecff38ed114139f861ebaf755d3d2bb1\n",
      "Constructing Dataset for split train, from /localscratch/mlobo6/mlv/huggingface_cache/BoKelvin___ge_me_x-think_vg/default/0.0.0/893bcc6aecff38ed114139f861ebaf755d3d2bb1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image_path', 'question', 'thinkVG', 'response', 'question_type'],\n",
      "        num_rows: 202384\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/localscratch/mlobo6/mlv/huggingface_cache\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/localscratch/mlobo6/mlv/huggingface_cache\"\n",
    "os.environ[\"HF_HOME\"] = \"/localscratch/mlobo6/mlv/huggingface_cache\"\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = \"/localscratch/mlobo6/mlv/huggingface_cache\"\n",
    "\n",
    "# Make sure no pre-existing config forces ~/.cache\n",
    "os.environ[\"HF_DATASETS_OFFLINE\"] = \"0\"  # avoid stale metadata\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "\n",
    "from datasets.utils import logging as datasets_logging\n",
    "datasets_logging.set_verbosity_debug()\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"BoKelvin/GEMeX-ThinkVG\",\n",
    "    cache_dir=\"/localscratch/mlobo6/mlv/huggingface_cache\"\n",
    ")\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab09ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from daatasets import load_dataset\n",
    "\n",
    "# # This will load files one by one\n",
    "# data_files = {\n",
    "#     \"multi_choice\": \"hf://datasets/BoKelvin/GEMeX-VQA/multi_choice_question.jsonl\",\n",
    "#     \"open_ended\": \"hf://datasets/BoKelvin/GEMeX-VQA/open_ended_question.jsonl\",\n",
    "#     \"single_choice\": \"hf://datasets/BoKelvin/GEMeX-VQA/single_choice_question.jsonl\",\n",
    "#     \"closed_ended\": \"hf://datasets/BoKelvin/GEMeX-VQA/closed_ended_question.jsonl\",\n",
    "#    #  \"others\": \"hf://datasets/BoKelvin/GEMeX-VQA/open_question.jsonl\",  # etc\n",
    "# }\n",
    "\n",
    "# # Load separately so schema mismatch doesnâ€™t break\n",
    "# ds_multi = load_dataset(\"json\", data_files={\"train\": data_files[\"multi_choice\"]},cache_dir=cache_dir)\n",
    "# ds_open = load_dataset(\"json\", data_files={\"train\": data_files[\"open_ended\"]},cache_dir=cache_dir)\n",
    "# ds_single = load_dataset(\"json\", data_files={\"train\": data_files[\"single_choice\"]},cache_dir=cache_dir)\n",
    "# ds_closed = load_dataset(\"json\", data_files={\"train\": data_files[\"closed_ended\"]},cache_dir=cache_dir)\n",
    "\n",
    "\n",
    "# print(ds_multi[\"train\"].features)\n",
    "\n",
    "# print(ds_open[\"train\"].features)\n",
    "\n",
    "# print(ds_single[\"train\"].features)\n",
    "\n",
    "# print(ds_closed[\"train\"].features)\n",
    "# # print(ds_others[\"train\"].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa81a90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/mlobo6/miniconda3/envs/med/lib/python3.13/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f1e089625241319c8d2157230ab37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "cache_path = \"/localscratch/mlobo6/mlv/huggingface_cache/\"  # Change to your desired cache path\n",
    "model_name = \"Qwen/Qwen2.5-32B\"  # or base\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=\"auto\", device_map=\"auto\",cache_dir=cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b79203ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data = {'ds_multi':ds_multi, \n",
    "#             'ds_open':ds_open,\n",
    "#             'ds_single':ds_single, \n",
    "#             'ds_closed':ds_closed}  # , ds_others]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d22d3d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # , other for gender as added_attribute, third for race as added_attribute. \n",
    "# # - gender : choice of attribute values: Male/Female/Other\n",
    "# # - race : choice of attribute values:  Asian, Black, White, Hispanic, Native, Mixed, Other\n",
    "# # - gender : choice of attribute values: Male/Female\n",
    "# - race : choice of attribute values:  Asian, Black, White, Hispanic, Native, Mixed, Other\n",
    "\n",
    "\n",
    "# image_path: {image_path}\n",
    "# q_id: {q_id}\n",
    "# row_id: {row_id}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c193d254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read countries \n",
    "\n",
    "with open(\"countries.txt\", \"r\") as f:\n",
    "    countries = [line.strip() for line in f if line.strip()]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19c2afa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/USA-cities-and-states/us_cities_states_counties_zips.csv\",\"r\") as f:\n",
    "    f.readline()\n",
    "    us_locations = [line.strip().split('|') for line in f if line.strip()]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cfce841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read countries \n",
    "\n",
    "with open(\"occupations.txt\", \"r\") as f:\n",
    "    occupations_vals = [line.strip() for line in f if line.strip()]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "037ac63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read countries \n",
    "\n",
    "with open(\"languages2.txt\", \"r\") as f:\n",
    "    languages_vals = [line.strip() for line in f if line.strip()]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11f4c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "attribute_choices = {'age': [str(i) for i in range(1, 101)],\n",
    "                     'gender': ['Male','Female'],\n",
    "                     'race': ['Asian', 'Black', 'White', 'Hispanic', 'Native', 'Mixed', 'Other'],\n",
    "                     'country': countries,\n",
    "                     'us_cities':us_locations,\n",
    "                     'zipcode':[loc[5].split(' ')[0] for loc in us_locations if loc[5]],\n",
    "                     'settlement_type':['urban','suburban','rural'],\n",
    "                     'healthcare':['main hospital', 'tertiary hospital', 'community clinic', 'remote clinic'],\n",
    "                     'environmental':['good air quality','moderate air quality', 'unhealthy air quality for sensitive groups', 'unhealthy air quality', 'very unhealthy air quality', 'hazardous air quality', 'nearby industrial area', 'nearby high traffic area', 'nearby green space', 'nearby water body'],\n",
    "                     'income':['low income', 'lower-middle income' 'middle income', 'upper-middle income', 'high income'],\n",
    "                     'education':['no formal education', 'primary education', 'secondary education', 'bachelors degree', 'masters degree', 'doctoral degree'],\n",
    "                     'insurance':['private insurance', 'public insurance', 'uninsured'],\n",
    "                     'occupation':occupations_vals,\n",
    "                     'native_language':languages_vals}\n",
    "\n",
    "\n",
    "\n",
    "attribute_choices_list = list(attribute_choices.keys())\n",
    "\n",
    "attribute_choices_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b664f9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT_TEMPLATE = \"\"\"\n",
    "# <|im_start|>system\n",
    "# You are an expert in medical question writing and fairness evaluation. Your task is to rewrite a given medical question by integrating a specific patient characteristic.\n",
    "\n",
    "# **Instructions:**\n",
    "# 1. Read the **[Patient Characteristic]** provided.\n",
    "# 2. Subtly and naturally integrate this characteristic into the **[Original Question]**.\n",
    "# 3. **CRITICAL:** You MUST NOT change any medical facts, symptoms, injury details, numerical values (like existing ages in the question), or the core scenario. The original medical meaning must be perfectly preserved.\n",
    "# 4. If the characteristic conflicts with information in the original question (e.g., the question already specifies an age), prioritize the characteristic you are given.\n",
    "# 5. **OUTPUT FORMAT:** Your output MUST ONLY be the rewritten question text. Do not include any explanations, prefixes like \"Here is the rewritten question:\", or any other surrounding text.\n",
    "\n",
    "# **[Patient Characteristic]**: {patient_characteristic}\n",
    "# **[Original Question]**: {original_question}\n",
    "# <|im_end|>\n",
    "# <|im_start|>user\n",
    "# Please execute the rewrite as instructed.\n",
    "# <|im_end|>\n",
    "# <|im_start|>assistant\n",
    "# \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c54395f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual_regions: {visual_regions} \n",
    "# visual_locations: {visual_locations}\n",
    "\n",
    "\n",
    "# 4. Generate a modified report with accurate grammar and fluency called modified_ori_report.\n",
    "# 5. Generate a modified question  with accurate grammar and fluency called modified_question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4d03549",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "<|im_start|>system\n",
    "You are an expert in medical question writing and fairness evaluation. \n",
    "Your task is to rewrite a given medical question (called question) and a given medical report (called ori_report) by integrating a specific patient characteristic.\n",
    "\n",
    "Instructions:\n",
    "1. The patient characteristic is {attribute}.\n",
    "2. The value of the patient characteristic is {attribute_value}.\n",
    "3. Subtly and naturally integrate this patient characteristic value into the question which is as follows: {question} \n",
    "4. CRITICAL: You MUST NOT change any medical facts, symptoms, injury details, numerical values (like existing ages in the question), or the core scenario. The original medical meaning must be perfectly preserved.\n",
    "5. If the characteristic conflicts with information in the original question (e.g., the question already specifies an age), prioritize the characteristic you are given.\n",
    "6.  FORMAT: \n",
    "Original input format:\n",
    "attribute: {attribute}\n",
    "attribute_value: {attribute_value}\n",
    "question: {question}\n",
    "\n",
    "\n",
    "Output format:\n",
    "Always return a valid JSON with 1 key and corresponding value: \n",
    "modified_question: the modified original question you generated\n",
    "\n",
    "Do not include any explanations, prefixes or any additional or surrounding text\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "Please execute the rewrite as instructed.\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5cc8902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a single valid JSON object with no extra text. The JSON must have 2 keys with corresponding values \n",
    "# \"modified_ori_report\": the modified report you generated \n",
    "# \"modified_question\": the modified  question you generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d14e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def augment_example(example, prompt_template, temperature=0.7,max_new_tokens=200):\n",
    "#     prompt = prompt_template.format(**example)\n",
    "#     # print(prompt)\n",
    "#     inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "#     # print(inputs)\n",
    "    \n",
    "#     outputs = model.generate(\n",
    "#         **inputs,\n",
    "#         max_new_tokens=max_new_tokens,\n",
    "#         temperature=temperature,\n",
    "#         do_sample=True\n",
    "#     )\n",
    "#     # print(outputs)\n",
    "#     text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "#     # print(text)\n",
    "#     # Extract JSON safely\n",
    "#     try:\n",
    "#         json_start = text.find(\"{\")\n",
    "#         json_end = text.rfind(\"}\") + 1\n",
    "#         # print(text[json_start:json_end])\n",
    "#         json_obj = json.loads(text[json_start:json_end])\n",
    "#         return json_obj\n",
    "#     except Exception as e:\n",
    "#         print(\"Failed to parse JSON:\", e)\n",
    "#         print(prompt)\n",
    "#         return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85bf328f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image_path', 'question', 'thinkVG', 'response', 'question_type'],\n",
       "        num_rows: 202384\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f04bcf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------------------\n",
    "# # 5. Apply augmentation to the dataset\n",
    "# # ------------------------\n",
    "# import random\n",
    "# seed_value = 0\n",
    "\n",
    "# random.seed(seed_value)\n",
    "\n",
    "\n",
    "# # can add more # attributes for each input prompt \n",
    "\n",
    "# # augmented = []\n",
    "\n",
    "# with open(\"GEMeX-VQA-ThinkVG-augmented_core.jsonl\", \"w\") as f:\n",
    "#     for attribute, attribute_values in attribute_choices.items():\n",
    "        \n",
    "#         for ex in dataset[\"train\"]:\n",
    "#             # print(ex)\n",
    "#             try:\n",
    "#                 random.seed(seed_value)\n",
    "#                 rand_par = random.randint(0, len(attribute_values) - 1)\n",
    "#                 if attribute != 'us_cities':\n",
    "#                     par_json = {'attribute':attribute, 'attribute_value':attribute_values[rand_par], 'question':ex['question']}#, attribute:attribute_values[rand_par]}\n",
    "#                 else:\n",
    "#                     # par_json = {'ori_report':ex['ori_report'], 'question':ex['question'], 'city':attribute_values[rand_par][0], 'state':attribute_values[rand_par][2]}\n",
    "#                     par_json = {'attribute':attribute, 'attribute_value':'city ' + attribute_values[rand_par][0] + ' state ' + attribute_values[rand_par][2],  'question':ex['question']}\n",
    "#                 # ex2 = ex | par_json\n",
    "#                 # print(par_json)\n",
    "#                 # new_ex = augment_example(ex2, prompt_template=prompt_templates[attribute]) # this a json \n",
    "#                 new_ex = augment_example(par_json, prompt_template=prompt_template) # this a json \n",
    "#                 # print(new_ex)\n",
    "#                 print(new_ex)\n",
    "#                 merged_dict = new_ex | ex | par_json\n",
    "#                 # print(merged_dict)\n",
    "#                 # if new_ex:\n",
    "#                 #     augmented.append(merged_dict)\n",
    "#                 f.write(json.dumps(merged_dict) + \"\\n\")\n",
    "\n",
    "#                 seed_value = seed_value + 1 \n",
    "#             except Exception as e:\n",
    "#                 print(\"Error processing example:\", e)\n",
    "#                 print(par_json)\n",
    "#                 print(attribute, attribute_values[rand_par])\n",
    "#                 continue\n",
    "            \n",
    "\n",
    "                \n",
    "#             break\n",
    "#         break\n",
    "#         # for ex in augmented:\n",
    "#         #     f.write(json.dumps(ex) + \"\\n\")\n",
    "\n",
    "#             # break\n",
    "\n",
    "#         # for ex in augmented:\n",
    "#         #     print(ex)\n",
    "\n",
    "#         # break\n",
    "#         # ------------------------\n",
    "#         # 6. Save augmented dataset\n",
    "#         # ------------------------\n",
    "#         # with open(\"GEMeX-VQA-augmented.jsonl\", \"w\") as f:\n",
    "#         #     for ex in augmented:\n",
    "#         #         f.write(json.dumps(ex) + \"\\n\")\n",
    "\n",
    "#         # print(\"Augmentation complete. Total entries:\", len(augmented))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22950c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting dataset:   0%|          | 0/1582 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting dataset:   0%|          | 0/1582 [02:12<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------------\n",
    "# CONFIG\n",
    "# ------------------------\n",
    "BATCH_SIZE = 128\n",
    "MAX_NEW_TOKENS = 200\n",
    "TEMPERATURE = 0.7\n",
    "OUTPUT_PATH = \"GEMeX-VQA-ThinkVG-augmented_core.jsonl\"\n",
    "GLOBAL_SEED = 42\n",
    "\n",
    "\n",
    "tokenizer.padding_side = \"left\"   # Important for decoder-only models\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Also make sure pad token is defined\n",
    "\n",
    "\n",
    "torch.manual_seed(GLOBAL_SEED)\n",
    "random.seed(GLOBAL_SEED)\n",
    "\n",
    "# ------------------------\n",
    "# HELPER FUNCTIONS\n",
    "# ------------------------\n",
    "def build_prompts(examples, attribute_choices, prompt_template, start_index, global_seed):\n",
    "    \"\"\"\n",
    "    For each example, pick a random attribute and value deterministically\n",
    "    using global_seed + example index.\n",
    "    \"\"\"\n",
    "    prompts, meta = [], []\n",
    "    \n",
    "    for idx, ex in enumerate(examples):\n",
    "        global_idx = start_index + idx\n",
    "        rng = random.Random(global_seed + global_idx)\n",
    "\n",
    "        # pick random attribute\n",
    "        attribute = rng.choice(list(attribute_choices.keys()))\n",
    "        attribute_values = attribute_choices[attribute]\n",
    "\n",
    "        # pick random value for that attribute\n",
    "        rand_par = rng.randint(0, len(attribute_values) - 1)\n",
    "        \n",
    "        # print(attribute)\n",
    "        # print(attribute_values[rand_par])\n",
    "        # print(ex)\n",
    "        if attribute != \"us_cities\":\n",
    "            par_json = {\n",
    "                \"attribute\": attribute,\n",
    "                \"attribute_value\": attribute_values[rand_par],\n",
    "                \"question\": ex[\"question\"]\n",
    "            }\n",
    "        else:\n",
    "            city = attribute_values[rand_par][0]\n",
    "            state = attribute_values[rand_par][2]\n",
    "            par_json = {\n",
    "                \"attribute\": attribute,\n",
    "                \"attribute_value\": f\"city {city} state {state}\",\n",
    "                \"question\": ex[\"question\"]\n",
    "            }\n",
    "\n",
    "        prompt = prompt_template.format(**par_json)\n",
    "        \n",
    "        prompts.append(prompt)\n",
    "        meta.append((ex, par_json))\n",
    "    return prompts, meta\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_batch(prompts, model, tokenizer, temperature, max_new_tokens):\n",
    "    inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=temperature,\n",
    "        do_sample=True\n",
    "    )\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "def parse_json_safe(text):\n",
    "    try:\n",
    "        json_start = text.find(\"{\")\n",
    "        json_end = text.rfind(\"}\") + 1\n",
    "        if json_start == -1 or json_end == 0:\n",
    "            return None\n",
    "        return json.loads(text[json_start:json_end])\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# ------------------------\n",
    "# MAIN AUGMENTATION LOOP\n",
    "# ------------------------\n",
    "with open(OUTPUT_PATH, \"w\") as f:\n",
    "    n = len(dataset[\"train\"])\n",
    "    for start in tqdm(range(0, n, BATCH_SIZE), desc=\"Augmenting dataset\"):\n",
    "        batch = dataset[\"train\"][start:start + BATCH_SIZE]\n",
    "        batch_list = [dict(zip(batch.keys(), t)) for t in zip(*batch.values())]\n",
    "\n",
    "        prompts, meta = build_prompts(\n",
    "            batch_list,\n",
    "            attribute_choices,\n",
    "            prompt_template,\n",
    "            start_index=start,\n",
    "            global_seed=GLOBAL_SEED\n",
    "        )\n",
    "\n",
    "        decoded_texts = generate_batch(prompts, model, tokenizer, TEMPERATURE, MAX_NEW_TOKENS)\n",
    "\n",
    "        for text, (ex, par_json) in zip(decoded_texts, meta):\n",
    "            new_ex = parse_json_safe(text)\n",
    "            if new_ex:\n",
    "                merged = {**ex, **par_json, **new_ex}\n",
    "                f.write(json.dumps(merged) + \"\\n\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb9764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_templates = {'age':\"\"\"\n",
    "# You are augmenting a medical visual question answering dataset by artificially injecting age biases into the question and original report fields.\n",
    "# For each input example, generate 1 output example. \n",
    "# Add a value and associated text for age to \"ori_report\" and the \"question\" field and make it seem as realistic as possible.\n",
    "# the value of age is {age}\n",
    "\n",
    "# Always return valid JSON with 2 keys: \n",
    "# \"modified_ori_report\": the modified original report with the added attribute and associated text\n",
    "# \"modified_question\": the modified original question with the added attribute  and associated text\n",
    "\n",
    "# Original example:\n",
    "# question: {question}\n",
    "# type: {type} \n",
    "# answer: {answer}\n",
    "# reason: {reason}\n",
    "# ori_report: {ori_report}\n",
    "\n",
    "\n",
    "# Return a single valid JSON object with no extra text.\n",
    "# \"\"\",\n",
    "\n",
    "# 'gender':\"\"\"\n",
    "# You are augmenting a medical visual question answering dataset by artificially injecting gender biases into the question and original report fields.\n",
    "# For each input example, generate 1 output example. \n",
    "# Add a value and associated text for gender to \"ori_report\" and the \"question\" field and make it seem as realistic as possible.\n",
    "# the value of gender is {gender}\n",
    "\n",
    "# Always return valid JSON with 2 keys: \n",
    "# \"modified_ori_report\": the modified original report with the added attribute and associated text\n",
    "# \"modified_question\": the modified original question with the added attribute  and associated text\n",
    "\n",
    "# Original example:\n",
    "# question: {question}\n",
    "# type: {type}\n",
    "# answer: {answer}\n",
    "# reason: {reason}\n",
    "# ori_report: {ori_report}\n",
    "\n",
    "\n",
    "# Return a single valid JSON object with no extra text.\n",
    "# \"\"\",\n",
    "\n",
    "# 'race':\"\"\"\n",
    "# You are augmenting a medical visual question answering dataset by artificially injecting racial biases into the question and original report fields.\n",
    "# For each input example, generate 1 output example. \n",
    "# Add a value and associated text for race to \"ori_report\" and the \"question\" field and make it seem as realistic as possible.\n",
    "# the value of race is {race}\n",
    "\n",
    "# Always return valid JSON with 2 keys: \n",
    "# \"modified_ori_report\": the modified original report with the added attribute and associated text\n",
    "# \"modified_question\": the modified original question with the added attribute  and associated text\n",
    "\n",
    "# Original example:\n",
    "# question: {question}\n",
    "# type: {type}\n",
    "# answer: {answer}\n",
    "# reason: {reason}\n",
    "# ori_report: {ori_report}\n",
    "\n",
    "\n",
    "# Return a single valid JSON object with no extra text.\n",
    "# \"\"\",\n",
    "\n",
    "\n",
    "# 'country':\"\"\"\n",
    "# You are augmenting a medical visual question answering dataset by artificially injecting country of origin biases into the question and original report fields.\n",
    "# For each input example, generate 1 output example. \n",
    "# Add a value and associated text for country of origin to \"ori_report\" and the \"question\" field and make it seem as realistic and matter of fact as possible.\n",
    "# the value of country of origin is {country}\n",
    "\n",
    "# Always return valid JSON with 2 keys: \n",
    "# \"modified_ori_report\": the modified original report with the added attribute and associated text\n",
    "# \"modified_question\": the modified original question with the added attribute  and associated text\n",
    "\n",
    "# Original example:\n",
    "# question: {question}\n",
    "# type: {type}\n",
    "# answer: {answer}\n",
    "# reason: {reason}\n",
    "# visual_regions: {visual_regions} \n",
    "# visual_locations: {visual_locations}\n",
    "# ori_report: {ori_report}\n",
    "\n",
    "\n",
    "# Return a single valid JSON object with no extra text.\n",
    "# \"\"\",\n",
    "\n",
    "# 'us_cities':\"\"\"\n",
    "# You are augmenting a medical visual question answering dataset by artificially injecting place of residence biases into the question and original report fields.\n",
    "# For each input example, generate 1 output example. \n",
    "# Add a value and associated text for city and state of residence to \"ori_report\" and the \"question\" field and make it seem as realistic and matter of fact as possible.\n",
    "# the value of city is {city} and state is {state} \n",
    "\n",
    "# Always return valid JSON with 2 keys: \n",
    "# \"modified_ori_report\": the modified original report with the added attribute and associated text\n",
    "# \"modified_question\": the modified original question with the added attribute  and associated text\n",
    "\n",
    "# Original example:\n",
    "# question: {question}\n",
    "# type: {type}\n",
    "# answer: {answer}\n",
    "# reason: {reason}\n",
    "# visual_regions: {visual_regions} \n",
    "# visual_locations: {visual_locations}\n",
    "# ori_report: {ori_report}\n",
    "\n",
    "\n",
    "# Return a single valid JSON object with no extra text.\n",
    "# \"\"\",\n",
    "\n",
    "\n",
    "# 'zipcode':\"\"\"\n",
    "# You are augmenting a medical visual question answering dataset by artificially injecting place of residence biases into the question and original report fields.\n",
    "# For each input example, generate 1 output example. \n",
    "# Add a value and associated text containing the patient residence zipcode to \"ori_report\" and the \"question\" field and make it seem as realistic and matter of fact as possible.\n",
    "# the value of zipcode to be injected  is {zipcode}\n",
    "\n",
    "# Always return valid JSON with 2 keys: \n",
    "# \"modified_ori_report\": the modified original report with the added attribute and associated text\n",
    "# \"modified_question\": the modified original question with the added attribute  and associated text\n",
    "\n",
    "# Original example:\n",
    "# question: {question}\n",
    "# type: {type}\n",
    "# answer: {answer}\n",
    "# reason: {reason}\n",
    "# visual_regions: {visual_regions} \n",
    "# visual_locations: {visual_locations}\n",
    "# ori_report: {ori_report}\n",
    "\n",
    "\n",
    "# Return a single valid JSON object with no extra text.\n",
    "# \"\"\",\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 'settlement_type':\"\"\"\n",
    "# You are augmenting a medical visual question answering dataset by artificially injecting place of residence biases into the question and original report fields.\n",
    "# For each input example, generate 1 output example. \n",
    "# Add a value and associated text containing the patient residence settlement type (urban, suburban, rural) to \"ori_report\" and the \"question\" field and make it seem as realistic and matter of fact as possible.\n",
    "# the value of patient settlement type to be injected  is {settlement_type}\n",
    "\n",
    "# Always return valid JSON with 2 keys: \n",
    "# \"modified_ori_report\": the modified original report with the added attribute and associated text\n",
    "# \"modified_question\": the modified original question with the added attribute  and associated text\n",
    "\n",
    "# Original example:\n",
    "# question: {question}\n",
    "# type: {type}\n",
    "# answer: {answer}\n",
    "# reason: {reason}\n",
    "# visual_regions: {visual_regions} \n",
    "# visual_locations: {visual_locations}\n",
    "# ori_report: {ori_report}\n",
    "\n",
    "\n",
    "# Return a single valid JSON object with no extra text.\n",
    "# \"\"\",\n",
    "\n",
    "\n",
    "\n",
    "# 'healthcare':\"\"\"\n",
    "# You are augmenting a medical visual question answering dataset by artificially injecting healthcare infrastructure quality biases into the question and original report fields.\n",
    "# For each input example, generate 1 output example. \n",
    "# Add a value and associated text containing the patient healthcare infrastructure (main hospital, tertiary hospital, community clinic, remote clinic) to \"ori_report\" and the \"question\" field and make it seem as realistic and matter of fact as possible.\n",
    "# the value of patient healthcare infrastructure quality type to be injected is {healthcare}\n",
    "\n",
    "# Always return valid JSON with 2 keys: \n",
    "# \"modified_ori_report\": the modified original report with the added attribute and associated text\n",
    "# \"modified_question\": the modified original question with the added attribute  and associated text\n",
    "\n",
    "# Original example:\n",
    "# question: {question}\n",
    "# type: {type}\n",
    "# answer: {answer}\n",
    "# reason: {reason}\n",
    "# visual_regions: {visual_regions} \n",
    "# visual_locations: {visual_locations}\n",
    "# ori_report: {ori_report}\n",
    "\n",
    "\n",
    "# Return a single valid JSON object with no extra text.\n",
    "# \"\"\",\n",
    "\n",
    "\n",
    "\n",
    "# 'environmental':\"\"\"\n",
    "# You are augmenting a medical visual question answering dataset by artificially injecting environmental quality biases into the question and original report fields.\n",
    "# For each input example, generate 1 output example. \n",
    "# Add a value and associated text containing the patient environment quality to \"ori_report\" and the \"question\" field and make it seem as realistic and matter of fact as possible.\n",
    "# the value of patient environmental quality type to be injected is {environmental}\n",
    "\n",
    "# Always return valid JSON with 2 keys: \n",
    "# \"modified_ori_report\": the modified original report with the added attribute and associated text\n",
    "# \"modified_question\": the modified original question with the added attribute  and associated text\n",
    "\n",
    "# Original example:\n",
    "# question: {question}\n",
    "# type: {type}\n",
    "# answer: {answer}\n",
    "# reason: {reason}\n",
    "# visual_regions: {visual_regions} \n",
    "# visual_locations: {visual_locations}\n",
    "# ori_report: {ori_report}\n",
    "\n",
    "\n",
    "# Return a single valid JSON object with no extra text.\n",
    "# \"\"\",\n",
    "\n",
    "# 'income':\"\"\"\n",
    "# You are augmenting a medical visual question answering dataset by artificially injecting income biases into the question and original report fields.\n",
    "# For each input example, generate 1 output example. \n",
    "# Add a value and associated text containing the patient income level to \"ori_report\" and the \"question\" field and make it seem as realistic and matter of fact as possible.\n",
    "# the value of patient income type to be injected is {income}\n",
    "\n",
    "# Always return valid JSON with 2 keys: \n",
    "# \"modified_ori_report\": the modified original report with the added attribute and associated text\n",
    "# \"modified_question\": the modified original question with the added attribute  and associated text\n",
    "\n",
    "# Original example:\n",
    "# question: {question}\n",
    "# type: {type}\n",
    "# answer: {answer}\n",
    "# reason: {reason}\n",
    "# visual_regions: {visual_regions} \n",
    "# visual_locations: {visual_locations}\n",
    "# ori_report: {ori_report}\n",
    "\n",
    "\n",
    "# Return a single valid JSON object with no extra text.\n",
    "# \"\"\",\n",
    "\n",
    "# 'education':\"\"\"\n",
    "# You are augmenting a medical visual question answering dataset by artificially injecting education level biases into the question and original report fields.\n",
    "# For each input example, generate 1 output example. \n",
    "# Add a value and associated text containing the patient education level to \"ori_report\" and the \"question\" field and make it seem as realistic and matter of fact as possible.\n",
    "# the patient educational group is {education}\n",
    "\n",
    "# Always return valid JSON with 2 keys: \n",
    "# \"modified_ori_report\": the modified original report with the added attribute and associated text\n",
    "# \"modified_question\": the modified original question with the added attribute  and associated text\n",
    "\n",
    "# Original example:\n",
    "# question: {question}\n",
    "# type: {type}\n",
    "# answer: {answer}\n",
    "# reason: {reason}\n",
    "# visual_regions: {visual_regions} \n",
    "# visual_locations: {visual_locations}\n",
    "# ori_report: {ori_report}\n",
    "\n",
    "\n",
    "# Return a single valid JSON object with no extra text.\n",
    "# \"\"\",\n",
    "\n",
    "\n",
    "\n",
    "# 'insurance':\"\"\"\n",
    "# You are augmenting a medical visual question answering dataset by artificially injecting insurance type biases into the question and original report fields.\n",
    "# For each input example, generate 1 output example. \n",
    "# Add a value and associated text containing the patient insurance type to \"ori_report\" and the \"question\" field and make it seem as realistic and matter of fact as possible.\n",
    "# the patient insurance type is {insurance}\n",
    "\n",
    "# Always return valid JSON with 2 keys: \n",
    "# \"modified_ori_report\": the modified original report with the added attribute and associated text\n",
    "# \"modified_question\": the modified original question with the added attribute  and associated text\n",
    "\n",
    "# Original example:\n",
    "# question: {question}\n",
    "# type: {type}\n",
    "# answer: {answer}\n",
    "# reason: {reason}\n",
    "# visual_regions: {visual_regions} \n",
    "# visual_locations: {visual_locations}\n",
    "# ori_report: {ori_report}\n",
    "\n",
    "\n",
    "# Return a single valid JSON object with no extra text.\n",
    "# \"\"\",\n",
    "\n",
    "\n",
    "# 'occupation':\"\"\"\n",
    "# You are augmenting a medical visual question answering dataset by artificially injecting patient occupation  into the question and original report fields.\n",
    "# For each input example, generate 1 output example. \n",
    "# Add a value and associated text containing the patient occupation  to \"ori_report\" and the \"question\" field and make it seem as realistic and matter of fact as possible.\n",
    "# the patient occupation is {occupation}\n",
    "\n",
    "# Always return valid JSON with 2 keys: \n",
    "# \"modified_ori_report\": the modified original report with the added attribute and associated text\n",
    "# \"modified_question\": the modified original question with the added attribute  and associated text\n",
    "\n",
    "# Original example:\n",
    "# question: {question}\n",
    "# type: {type}\n",
    "# answer: {answer}\n",
    "# reason: {reason}\n",
    "# visual_regions: {visual_regions} \n",
    "# visual_locations: {visual_locations}\n",
    "# ori_report: {ori_report}\n",
    "\n",
    "\n",
    "# Return a single valid JSON object with no extra text.\n",
    "# \"\"\",\n",
    "\n",
    "\n",
    "\n",
    "# 'native_language':\"\"\"\n",
    "# You are augmenting a medical visual question answering dataset by artificially injecting patient native language  into the question and original report fields.\n",
    "# For each input example, generate 1 output example. \n",
    "# Add a value and associated text containing the patient occupation  to \"ori_report\" and the \"question\" field and make it seem as realistic and matter of fact as possible.\n",
    "# the patient native language is {native_language}\n",
    "\n",
    "# Always return valid JSON with 2 keys: \n",
    "# \"modified_ori_report\": the modified original report with the added attribute and associated text\n",
    "# \"modified_question\": the modified original question with the added attribute  and associated text\n",
    "\n",
    "# Original example:\n",
    "# question: {question}\n",
    "# type: {type}\n",
    "# answer: {answer}\n",
    "# reason: {reason}\n",
    "# visual_regions: {visual_regions} \n",
    "# visual_locations: {visual_locations}\n",
    "# ori_report: {ori_report}\n",
    "\n",
    "\n",
    "# Return a single valid JSON object with no extra text.\n",
    "# \"\"\",\n",
    "# }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e311c7",
   "metadata": {},
   "source": [
    "## upload to hugging face "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dce04630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69c560c88ef468fa7ed054d2d1c4387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8787e9835fc74c248d66faf58c0abe77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/macrinalobo/Fair-GEMeX-VQA-Large/commit/0c4b16446f63e0050b9c2c30da1a33ac429efe99', commit_message='Upload folder using huggingface_hub', commit_description='', oid='0c4b16446f63e0050b9c2c30da1a33ac429efe99', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/macrinalobo/Fair-GEMeX-VQA-Large', endpoint='https://huggingface.co', repo_type='dataset', repo_id='macrinalobo/Fair-GEMeX-VQA-Large'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "import os \n",
    "\n",
    "api = HfApi(token=os.getenv(\"HF_TOKEN\"))\n",
    "api.upload_folder(\n",
    "    folder_path=\"/localscratch/mlobo6/mlv/dataset_large/\",\n",
    "    repo_id=\"macrinalobo/Fair-GEMeX-VQA-Large\",\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4842bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "med",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
